





import os
import mne
import numpy as np
import matplotlib.pyplot as plt
import pickle
import pandas as pd


from scipy import signal
from scipy.io import wavfile

# from pybv import write_brainvision
from pyprep.prep_pipeline import PrepPipeline
from mne_icalabel import label_components

# set working directory
work_dir = '/Users/chaohan/Library/CloudStorage/OneDrive-UniversityofToronto/Projects/Yas accent/'
# pc
# work_dir = '/Users/hanch/OneDrive - University of Toronto/Projects/Yas accent/'









# directory
input_dir = work_dir + 'data_raw/'
output_dir = work_dir + 'data_preprocessed/1_trigger_lag_fixed/'
# create a folder if the folder doesn't exist
os.makedirs(output_dir, exist_ok=True)

# create a dictionary for blocks and markers
block_dict = {
    'ChEn':1000, # standard: chinese; deviant: english
    'EnCh':2000, # standard: english; deviant: chinese
    'InEn':3000, # standard: indian; deviant: english
    'EnIn':4000, # standard: english, deviant: indian
}


# exclude participants with missing data
exclude_ppts = [
    '140', # no data
    '197', # no data
    
    '135', # incomplete data
    '179', # incomplete data
    '182', # incomplete data

    '141', # wrong experiment was run

    '261', # no StimTrak recording

    '271', # no stimtrak
    '272', # no stimtrak

    '115', # unknown
]

# trigger searching window (actual trigger time based on audio - trigger time in the data)
t_left = -0.01
t_right = 0.05


#######################################################
#### create a dictionary for trigger codes and descriptions ####
df = pd.read_csv("mapping.txt", delimiter='\t')
mapping = dict(zip(df['code'], df['description']))
#######################################################

#### create a trigger dictionary for each stim's standard version and deviant version ####

# intialize a dictionary for triggers
trigger_dict = {}

# read in trigger_codes file
with open('trigger_codes.txt','r') as tf:
    for line in tf:
        # read in the current line
        line = line.replace('\n','')
        # separate fileNames and triggerMarker
        label, marker = line.split('\t')
        # convert trigger markers to integer
        marker = int(marker)
        # create label for stims used as standards
        trigger_dict[marker] = label + '-s'
        # add 100 for deviant marker
        marker_deviant = marker + 100
        # create label for stims used as deviants
        trigger_dict[marker_deviant] = label + '-d'



#### trigger correction for each file ####

# initialize a dictionary to save bad stims
all_bad_stim_dict = {}

# read in eeg data files
all_files = os.listdir(input_dir)

#### for each file, create an all_block dictionary to store each block and the indices of trials of that block  ####
for file in all_files:
    if file.endswith(".vhdr") and (file.split('.')[0]+ '_corr.fif' not in os.listdir(output_dir)):

        # exclude bad data
        if (file.split('.')[0].split('_')[1] in exclude_ppts):
            continue
            
        # read in vhdr files
        raw = mne.io.read_raw_brainvision(input_dir + file, preload = True)

        # extract sampling rate
        eeg_sfreq = raw.info['sfreq']
        
        # If the aux channel is not named 'StimTrak', change the channel name to 'StimTrak'
        if raw.info['ch_names'][31] != 'StimTrak':
            # change the channel name
            raw.rename_channels({raw.info['ch_names'][31]: 'StimTrak'})
            # specify the audio channel
            raw.set_channel_types({'StimTrak':'misc'})

        ##########################################################################################
        #### get trigger code, audio data, create a trigger dictionary for each stim's standard version and deviant version ####

        # initialize dictionaries
        audio = {}
        lengths = {}
        
        # del trigger_dict[99999]
        for marker,label in trigger_dict.items():
            # extract file name
            file_name = label[:7]
            # if not already in audio dictionary, get the info of the audio file
            if file_name not in audio:
                # get sample rate and data of the audio file
                sampleRate, data = wavfile.read(work_dir + 'yas_exp/stimuli/{}.wav'.format(file_name))
                # calculate sound file length
                lengths[file_name] = len(data)/sampleRate
                # reduce the sampling rate of the audio file by the factor of int(sampleRate/eeg_freq)
                data_downsampled = signal.decimate(data,int(sampleRate/eeg_sfreq), ftype='fir')
                # add info the audio dictionary
                audio[file_name] = data_downsampled

        #### making events ####
        # for each stimulus, mark the block info
        events_from_annot, event_dict = mne.events_from_annotations(raw, verbose='WARNING')
        # remove useless markers (New Segment: 99999, pause: 222, and continue: 223)
        events_from_annot = events_from_annot[events_from_annot[:, 2] < 200]
                
        # initialize the train for each standards+deviant sequence
        train = np.array([]).astype(int)
        
        all_block = {}
        isStandard = True # whether the standard in a train has been noted
            
        # loop over each trigger
        for i in range(events_from_annot.shape[0]):
                
            # add the current token to the train
            train = np.append(train,i)

            # trigger code
            trigger_marker = events_from_annot[i,2]
            
            # if the trigger code is smaller than 100 and the standard note is true
            if (trigger_marker<100) & isStandard:
                # save the standard stim category
                block = trigger_dict[trigger_marker][:2]
                # toggle standard note
                standard = False

            # if the trigger value is over 100
            elif trigger_marker>100:
                # append the deviant stim category 
                block = block + trigger_dict[trigger_marker][:2]

                # if the block is not present in all block
                if block not in all_block:
                    # add the new block and the token idx
                    all_block[block] = train[2:] # [2:] to exclude the first 2 standards
                else:
                    # add the token idx to the existing block
                    all_block[block] = np.concatenate([ all_block[block], train[2:] ], axis=None)

                # reset train
                train = np.array([]).astype(int)

                # toggle standard note
                isStandard = True
        
        # loop over each block and its trigger index
        for k,v in all_block.items(): 
            # recode the trigger value to reflect block and stim category
            events_from_annot[tuple(v),2] += block_dict[k]

        # exclude the first 2 standards
        events_from_annot = events_from_annot[events_from_annot[:,2]>1000]
        ##########################################################################################
        
        ########################################################
        #### calculate cross correction to detect the delay ####
        
        # initialize delay list
        delays = np.array([])
        # initialize bad stim list
        bad_stim = []
        corr_results = []
        
        # loop over each event
        for i in range(events_from_annot.shape[0]):

            # get current event info [time, duration, annotation]
            event = events_from_annot[i]
            # get the onset latency (s) of the event
            time = event[0]/eeg_sfreq
            # get the file name of the event
            name = trigger_dict[event[2]%100].split('-')[0]
            # get the data from the sound channel
            audio_eeg = raw.get_data(
                picks = ['StimTrak'],
                tmin = time + t_left,
                tmax = time + lengths[name] + t_right,
            )[0]
            # actual stimulus
            audio_stim = audio[name]
            
            # Z-score normalization (subtract mean, divide by std)
            audio_eeg = (audio_eeg - np.mean(audio_eeg)) / np.std(audio_eeg)
            audio_stim = (audio_stim - np.mean(audio_stim)) / np.std(audio_stim)

            # cross-correlation
            corr = signal.correlate(audio_eeg, audio_stim, mode='full')
            # Normalize cross-correlation
            corr = corr / (np.linalg.norm(audio_eeg) * np.linalg.norm(audio_stim))
            # Find peak correlation value
            max_corr = np.max(corr)    
            
            # if the maximum correction (sum of products) is less than a threshold (empirical, but 0.5 is good for most cases)
            if max_corr < 0.5:
                # mark the stim bad
                bad_stim.append(i)
            
            # append the maximum correlation
            corr_results.append(max_corr)
            
            # the lags for cross-correlation
            lags = signal.correlation_lags(
                audio_eeg.size,
                audio_stim.size,
                mode="full")
            # get the lag of the maximum cross-correlation
            lag = lags[np.argmax(corr)] + t_left*eeg_sfreq
            
            # save the lag for non-starting events
            delays = np.append(delays, lag)
        ########################################################

        ##################################################################################################
        #### plot the wave from the stim track and the eeg channel of the token with the minimum corr ####
        
        min_corr = np.argmin(corr_results)
        # get current event info [time, duration, annotation]
        event = events_from_annot[min_corr]
        # get the onset latency (s) of the event
        time = event[0]/eeg_sfreq
        # get the file name of the event
        name = trigger_dict[event[2]%100].split('-')[0]
        # get the data from the sound channel
        audio_eeg = raw.get_data(
            picks = ['StimTrak'],
            tmin = time + t_left,
            tmax = time + lengths[name] + t_right,
        )[0]
        # actual stimulus
        audio_stim = audio[name]
        # Z-score normalization (subtract mean, divide by std)
        audio_eeg = (audio_eeg - np.mean(audio_eeg)) / np.std(audio_eeg)
        audio_stim = (audio_stim - np.mean(audio_stim)) / np.std(audio_stim)
        # plot
        fig, ax = plt.subplots()
        ax.plot(audio_eeg, label = 'StimTrak', alpha = 0.6)
        ax.plot(audio_stim, label = 'wave', alpha = 0.6)
        ax.set_title(file)
        ax.legend()
        fig.savefig(output_dir + file.split('.')[0] + "_minCor.png", dpi=300, bbox_inches='tight')
        ##################################################################################################

                
        ####################################################
        #### correct for trigger lag and save log files ####

        # add number of bad stim info
        all_bad_stim_dict[file] = len(bad_stim)

        # remove items associated with bad stims from the event list
        events_from_annot = np.delete(events_from_annot, bad_stim, 0)
        
        # remove items associated with bad stims from the delay list
        delays = np.delete(delays, bad_stim, 0)

        # add delay back to the onset latency of each event
        events_from_annot[:,0] = events_from_annot[:,0] + delays

        # # convert individual event marker to conditions
        # events_from_annot[:,2] = events_from_annot[:,2] - events_from_annot[:,2]%100

        # create annotations
        annot_from_events = mne.annotations_from_events(
            events = events_from_annot,
            event_desc = mapping,
            sfreq = raw.info['sfreq']
        )

        # set annotations
        raw.set_annotations(annot_from_events)
        
        # drop the audio channel in data
        raw.drop_channels(['StimTrak'])
        
        # save as a file-into-file data
        raw.save(output_dir + file.split('.')[0]+ '_corr.fif')
        
        # save lag data
        np.savetxt(output_dir + file.replace('.vhdr', '_delays.txt'), delays, fmt='%i')
        ####################################################
        

# save the number of bad stims of all participant
with open(output_dir + 'bad_stim.txt', 'a') as f:
    for key, value in all_bad_stim_dict.items():
        if value > 0:
            f.write(key + '\t' + str(value) + '\n')


events_from_annot








# set directory
input_dir = work_dir + 'data_preprocessed/1_trigger_lag_fixed/'
output_dir = work_dir + 'data_preprocessed/2_bad_channel_corrected/'
# create a folder if the folder doesn't exist
os.makedirs(output_dir, exist_ok=True)

# filter cutoff frequencies (low/high)
f_low = 1
f_high = 100

# resampling frequency
f_res = 250

# line frequency
line_freq = 60

# preprocessing parameters
prep_params = {
    "ref_chs": 'eeg',
    "reref_chs": 'eeg', # average re-reference
    "line_freqs": np.arange(line_freq, f_res/2, line_freq),
}

# create a montage file for the pipeline
montage = mne.channels.make_standard_montage("standard_1020")

# interpolation method
# method=dict(eeg="spline")

exclude_ppts = [
    '187', # too many bad stims
    '200', # too many bad stims
    '259', # too many bad stims
    '273', # too many bad stims
]


#####################################################
#### Preprocessing (filtering, resampling, bad channel detection/interpoloation, re-reference) ####
#####################################################

# get all file namesin the folder
all_input = os.listdir(input_dir)
all_output = os.listdir(output_dir)


for file in all_input:
    if file.endswith("corr.fif") and (file.split('_')[1] not in exclude_ppts) and (file.split('.')[0]+ '_prep.fif' not in all_output):
        
        # read in file
        raw = mne.io.read_raw_fif(input_dir + file, preload=True)
        
        # set channel type
        raw.set_channel_types({'Fp1':'eog', 'Fp2':'eog'})

        # filter
        raw.filter(l_freq = f_low, h_freq = f_high)
        
        #### cut off the beginning and ending part ####
        
        # get the onset of the first and the last event ####
        events_from_annot, event_dict = mne.events_from_annotations(raw, verbose='WARNING')

        # define the beginning time (in seconds)
        crop_start = events_from_annot[0][0]/raw.info['sfreq'] - 10

        # define the ending time (in seconds)
        crop_end = events_from_annot[-1][0]/raw.info['sfreq'] + 10

        # crop the data
        raw.crop(
            tmin=max(crop_start, raw.times[0]), 
            tmax=min(crop_end, raw.times[-1])
        )
        
        # resample
        raw.resample(sfreq = f_res)

        # read in channel location info
        raw.set_montage(montage)
        
        ####  Use PrePipeline to preprocess ####
        '''
        1. detect and interpolate bad channels
        2. remove line noise
        3. re-reference
        '''
        
        # apply pyprep
        prep = PrepPipeline(raw, prep_params, montage, random_state=42)
        prep.fit()

        
        # export a txt file for the interpolated channel info
        with open(output_dir + 'bad_channel.txt', 'a+') as f:
            _ =f.write(
                file + ':\n' +
                "- Bad channels original: {}".format(prep.noisy_channels_original["bad_all"]) + '\n' +
                "- Bad channels after robust average reference: {}".format(prep.interpolated_channels) + '\n' +
                "- Bad channels after interpolation: {}".format(prep.still_noisy_channels) + '\n'
            )

        # save the pypred preprocessed data into the raw data structure
        raw = prep.raw

        # spline interpolating remaining bad channels if any
        raw.interpolate_bads()

        # add back the reference channel
        raw = mne.add_reference_channels(raw,'TP9')

        # add the channel loc info (for the newly added reference channel)
        raw.set_montage(montage)
        
        # save
        raw.save(output_dir + file.split('.')[0]+ '_prep.fif')








# directory
input_dir = work_dir + 'data_preprocessed/2_bad_channel_corrected/'
output_dir = work_dir + 'data_preprocessed/3_ica/'

# create a folder if the folder doesn't exist
os.makedirs(output_dir, exist_ok=True)

# run ica on epoched data or continuous data
ica_input_type = 'epoch'
# ica_input_type = 'continuous'

# up to which IC you want to consider
ic_upto = 15
# ic_upto = 99

# Epoch window: 
erp_t_start = -0.1; erp_t_end = 0.9 # ERP: -100 ~ 700 ms



# get all file names in the folder
all_input = os.listdir(input_dir)
all_output = os.listdir(output_dir)


# for each file
for file in all_input:
    if file.endswith("prep.fif") and (file.split('.')[0]+ '_ica.fif' not in all_output): 
    
        # read in file
        raw = mne.io.read_raw_fif(input_dir + file, preload=True)
        
        # make a filtered file copy ICA. It works better on signals with 1 Hz high-pass filtered and 100 Hz low-pass filtered
        raw_filt = raw.copy().filter(l_freq = 1, h_freq = 100)
    
        # apply a common average referencing, to comply with the ICLabel requirements
        raw_filt.set_eeg_reference("average")

        # initialize ica components enough components to explain 0.999999 of the variance by default
        ica = mne.preprocessing.ICA(
            max_iter='auto', # n-1
            # use ‘extended infomax’ method for fitting the ICA, to comply with the ICLabel requirements
            method = 'infomax', 
            fit_params = dict(extended=True),
            random_state = 42,
        )

        # run ica on epochs or continuous
        if ica_input_type=="epoch":
            # get event info for segmentation
            events_from_annot, event_dict = mne.events_from_annotations(raw_filt, verbose='WARNING')
            # segmentation for ERP
            epochs = mne.Epochs(
                raw_filt,
                events = events_from_annot, event_id = event_dict,
                tmin = erp_t_start, tmax = erp_t_end,
                # apply baseline correction
                baseline = None,
                # remove epochs that meet the rejection criteria
                reject = None,
                preload = True,
            )
            # set ica_input
            ica_input = epochs
        else:
            ica_input = raw_filt
            
        #### get ica solution ####
        ica.fit(ica_input, picks = ['eeg'])
        #### ICLabel ####
        ic_labels = label_components(ica_input, ica, method="iclabel")
        
        # save ica solutions
        ica.save(output_dir + file.split('.')[0]+ '_icaSolution.fif', overwrite=True)

        # save
        with open(output_dir + file.split('.')[0]+ '_icLabels.pickle', 'wb') as f:
            pickle.dump(ic_labels, f)

        #### auto select brain AND other ####
        labels = ic_labels["labels"]
        exclude_idx = [
            idx for idx, label in enumerate(labels) if idx<ic_upto and label not in ["brain", "other"]
        ]
        
        # ica.apply() changes the Raw object in-place
        ica.apply(raw, exclude=exclude_idx)

        # record the bad ICs in bad_ICs.txt
        with open(output_dir + '/bad_ICs.txt', 'a+') as f:
            _ = f.write(file + '\t' + str(exclude_idx) + '\n')
        
        # save data after ICA
        raw.save(output_dir + file.split('.')[0]+ '_ica.fif')

        # release memory
        del raw, raw_filt, ica_input








# directory
input_dir = work_dir + 'data_preprocessed/3_ica/'
output_dir = work_dir + 'data_preprocessed/4_epochs/'
# create a folder if the folder doesn't exist
os.makedirs(output_dir, exist_ok=True)


# Epoch window: 
erp_t_start = -0.1; erp_t_end = 0.9

# criteria to reject epoch
reject_criteria = dict(eeg = 50e-6)       # 50 µV
# reject_criteria = dict(eeg = 100e-6)       # 100 µV
# reject_criteria = dict(eeg = 150e-6)       # 150 µV
# reject_criteria = dict(eeg = 200e-6)       # 200 µV


# get file names
all_input = os.listdir(input_dir)
all_output = os.listdir(output_dir)


#### re-reference, and epoch ####
for file in all_input:
    
    if file.endswith("ica.fif") and (file.split('.')[0] + '_epo.fif' not in all_output):
        
        # read in data
        raw = mne.io.read_raw_fif(input_dir + file, preload = True)
        
        # average-mastoids re-reference
        raw.set_eeg_reference(ref_channels = ['TP9', 'TP10'])
        
        #### this is for source calculation ####
        # filter the data, optional
        # raw = raw.filter(l_freq=None, h_freq=30) 

        # sphere = mne.make_sphere_model('auto', 'auto', raw.info)
        # src = mne.setup_volume_source_space(sphere=sphere, exclude=30., pos=15.)
        # forward = mne.make_forward_solution(raw.info, trans=None, src=src, bem=sphere)
        # raw = raw.set_eeg_reference('REST', forward=forward)
        ########################################
        
        # get event info for segmentation
        events_from_annot, event_dict = mne.events_from_annotations(raw, verbose='WARNING')
        
        # segmentation for ERP
        epochs = mne.Epochs(
            raw,
            events = events_from_annot, event_id = event_dict,
            tmin = erp_t_start, tmax = erp_t_end,
            # apply baseline correction
            baseline = None,
            # remove epochs that meet the rejection criteria
            reject = reject_criteria,
            preload = True,
        )

        # remove 0 trial events, record info, and check if a subject is bad
        for k, v in event_dict.items():

            # good trial count
            trial_count = len(epochs[k])

            # remove 0 trial event
            if trial_count==0:
                del epochs.event_id[k]

            # good trial rate
            goodTrial_rate = round( trial_count/sum(events_from_annot[:,2]==v), 2 )
            
            # record epoch summary
            with open(output_dir + 'epoch_summary.txt', 'a+') as f:
                _ =f.write(file.split('_')[1] + '\t' + k + '\t' + str(trial_count) + '\t' + str(goodTrial_rate) + '\n')

        # save single participant file
        epochs.save(output_dir + file.split('.')[0] + '_epo.fif',
                   overwrite=True)








# directory
input_dir = work_dir + 'data_preprocessed/4_epochs/'
output_dir = work_dir + 'data_preprocessed/5_evokeds/'
# create a folder if the folder doesn't exist
os.makedirs(output_dir, exist_ok=True)

# condition list
cond_list = [
    'ChEn-devi', 
    'ChEn-stan', 
    'EnCh-devi', 
    'EnCh-stan', 
    'EnIn-devi', 
    'EnIn-stan', 
    'InEn-devi', 
    'InEn-stan'
]

exclude_ppts = [
    '114' # too noisy
]

erp_baseline = (-0.1, 0)


#### get ERP ####

# get file names
all_input = os.listdir(input_dir)
all_output = os.listdir(output_dir)

# for each file
for file in all_input:
    
    if file.endswith("_epo.fif") and (file.split('_')[1]+'_ave.fif' not in all_output):
        
        # extract subject number
        ppt = file.split('_')[1]

        if ppt in exclude_ppts:
            continue

        # read in data
        epochs = mne.read_epochs(input_dir + file, preload = True)

        # get erp for each condition
        evoked_list = []
        for cond in cond_list:
            
            # average | get ERP for each condition
            evoked = epochs[cond].average(by_event_type=False)

            # add condition label
            evoked.comment = cond

            # apply baseline
            evoked.apply_baseline(baseline=erp_baseline)

            # append
            evoked_list.append(evoked)
        
        # save
        mne.write_evokeds(output_dir + ppt + '_ave.fif', evoked_list)
    
        # reduce memory usage
        del epochs, evoked, evoked_list








# directory
input_dir = work_dir + 'data_preprocessed/3_ica/'
output_dir = work_dir + 'data_preprocessed/4_tfr_evokeds_unnormalized/'
# create a folder if the folder doesn't exist
os.makedirs(output_dir, exist_ok=True)


# Epoch window: 
epoch_t_start = -1; epoch_t_end = 2

# criteria to reject epoch
reject_criteria = dict(eeg = 100e-6)       # 100 µV
# reject_criteria = dict(eeg = 150e-6)       # 150 µV
# reject_criteria = dict(eeg = 200e-6)       # 200 µV

exclude_ppts = [
    '114' # too noisy
]

tfr_method = 'morlet'

# frequencies
freq_start = 3
freq_end = 30
n_freq = 28
freqs = np.linspace(start=freq_start, stop=freq_end, num=n_freq)

# cycles
cycl_start = 3
cycl_step = 0.8
n_cycl = n_freq
n_cycles = np.linspace(start=cycl_start, stop=cycl_start+cycl_step*(n_cycl-1), num=n_cycl)

condition_list = ['ChEn-stan', 'ChEn-devi', 'EnCh-stan', 'EnCh-devi']


# initialize a list for subjects with too many bad trials
# get file names
all_input = os.listdir(input_dir)
all_output = os.listdir(output_dir)


#### re-reference, and epoch ####
for file in all_input:
    
    if file.endswith("ica.fif") and (file.split('_')[1] + '_tfr.hdf5' not in all_output):

        # skip bad participants
        if file.split('_')[1] in exclude_ppts:
            continue
        
        # read in data
        raw = mne.io.read_raw_fif(input_dir + file, preload = True)
        
        # average-mastoids re-reference
        raw.set_eeg_reference(ref_channels = ['TP9', 'TP10'])
        
        #### this is for source calculation ####
        # filter the data, optional
        # raw = raw.filter(l_freq=None, h_freq=30) 

        # sphere = mne.make_sphere_model('auto', 'auto', raw.info)
        # src = mne.setup_volume_source_space(sphere=sphere, exclude=30., pos=15.)
        # forward = mne.make_forward_solution(raw.info, trans=None, src=src, bem=sphere)
        # raw = raw.set_eeg_reference('REST', forward=forward)
        ########################################

        # pick EEG channels
        # picks = mne.pick_types(raw.info, eeg = True)
        
        # get event info for segmentation
        events_from_annot, event_dict = mne.events_from_annotations(raw, verbose='WARNING')
        
        # segmentation for ERP
        epochs = mne.Epochs(
            raw,
            events = events_from_annot, event_id = event_dict,
            tmin = epoch_t_start, tmax = epoch_t_end,
            # apply baseline correction
            baseline = None,
            # remove epochs that meet the rejection criteria
            reject = reject_criteria,
            preload = True,
        )
        


        # for each event, remove 0 trial events, record info, and check if a subject is bad
        for k, v in event_dict.items():

            # good trial count
            trial_count = len(epochs[k])

            # remove 0 trial event
            if trial_count==0:
                del epochs.event_id[k]

            # good trial rate
            goodTrial_rate = round( trial_count/sum(events_from_annot[:,2]==v), 2 )
            
            # record epoch summary
            with open(output_dir + 'epoch_summary.txt', 'a+') as f:
                _ =f.write(file.split('_')[1] + '\t' + k + '\t' + str(trial_count) + '\t' + str(goodTrial_rate) + '\n')


        # ERSP

        # initialize tfrs list
        tfrs = []
        
        for condition in condition_list:
            # compute ERSP
            power = epochs[condition].compute_tfr(
                method=tfr_method,
                freqs=freqs,
                n_cycles=n_cycles,
                # return_itc=True,
                decim=3,
            )
            
            # average
            power = power.average(method = 'mean', dim = 'epochs')

            # add comment
            power.comment = condition

            # append
            tfrs.append(power)
            
        # save single subject file
        mne.time_frequency.write_tfrs(fname=output_dir + file.split('_')[1] + '_tfr.hdf5', 
                                      tfr=tfrs)

        # release memory
        del power, tfrs








# directory
input_dir = work_dir + 'data_preprocessed/4_epochs/'
output_dir = work_dir + 'data_analysis/gam/'
# create a folder if the folder doesn't exist
os.makedirs(output_dir, exist_ok=True)

erp_baseline = (-0.1, 0)


#### get ERP ####

# get file names
all_input = os.listdir(input_dir)
all_output = os.listdir(output_dir)


# for each file
for file in all_input:
    
    if file.endswith("_epo.fif") and (file.split('_')[1]+'_gam.csv' not in all_output):

        # initialize panda dataframe
        df = pd.DataFrame()
        
        # extract subject number
        ppt = file.split('_')[1]

        # read in data
        epochs = mne.read_epochs(input_dir + file, preload = True)

        # get erp for each item
        for key in epochs.event_id.keys():
                        
            # average | get ERP for each condition
            evoked = epochs[key].average()

            # apply baseline
            evoked.apply_baseline(baseline=erp_baseline, verbose='WARNING')

            # append
            tmp_df = evoked.to_data_frame(time_format='ms')
            
            # add info of group, ppt, and item
            tmp_df['participant'] = ppt
            tmp_df['item'] = key

            # row bind data
            df = pd.concat([df, tmp_df])
        # save
        df.to_csv(output_dir + ppt + '_gam.csv', index=False)
        
        # reduce memory usage
        del df








# directory
input_dir = work_dir + 'data_preprocessed/ica_on_continuous_200mV_cutoff/4_epochs/'
output_dir = work_dir + 'data_analysis/erp/'
# create a folder if the folder doesn't exist
os.makedirs(output_dir, exist_ok=True)

# condition list
cond_list = [
    'ChEn-devi', 
    'ChEn-stan', 
    'EnCh-devi', 
    'EnCh-stan', 
    'EnIn-devi', 
    'EnIn-stan', 
    'InEn-devi', 
    'InEn-stan'
]

erp_baseline = (-0.1, 0)


#### get ERP ####

# get file names
all_input = os.listdir(input_dir)
all_output = os.listdir(output_dir)


# for each file
for file in all_input:
    
    if file.endswith("_epo.fif") and (file.split('_')[1]+'_erp.csv' not in all_output):

        # initialize panda dataframe
        df = pd.DataFrame()
        
        # extract subject number
        ppt = file.split('_')[1]

        # read in data
        epochs = mne.read_epochs(input_dir + file, preload = True)

        # get erp for each item
        for cond in cond_list:
                        
            # average | get ERP for each condition
            evoked = epochs[cond].average(by_event_type=False)

            # apply baseline
            evoked.apply_baseline(baseline=erp_baseline)

            # append
            tmp_df = evoked.to_data_frame(time_format='ms')
            
            # add info of group, ppt, and item
            tmp_df['participant'] = ppt
            tmp_df['condition'] = cond

            # row bind data
            df = pd.concat([df, tmp_df])
        # save
        df.to_csv(output_dir + ppt + '_erp.csv', index=False)



